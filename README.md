BikeStores Data Warehouse ProjectProject OverviewThis project represents a comprehensive end-to-end data solution. The primary goal was to transform raw transactional data from an Online Transaction Processing (OLTP) system into a structured Data Warehouse (DWH) optimized for business intelligence and reporting. The project encompasses the entire data lifecycle, from data ingestion and transformation to detailed analysis and interactive visualization.Project ArchitectureThe project follows a robust, multi-stage data pipeline designed for efficiency and scalability.Source: The BikeStores transactional database serves as the primary data source. This system, optimized for fast writes and daily operations, contains detailed sales, customer, and product information.ETL (Extract, Transform, Load): The data is processed using SSIS (SQL Server Integration Services) to perform complex transformations and load data incrementally into the Data Warehouse.Data Warehouse: The data is stored in a separate database modeled using a Star Schema, which is specifically designed to support fast and flexible analytical queries.Analysis: SQL is used as the primary tool for performing in-depth data analysis and generating insights.Visualization: Interactive and dynamic dashboards created with Power BI provide a user-friendly interface for stakeholders to explore the data and monitor key performance indicators (KPIs).Architecture Diagram<!-- Insert Image: [DWH Diagram.PNG] -->Image of the Data Warehouse architecture diagramDatabase ModelingThe project leverages two distinct database models: a transactional source and an analytical data warehouse. Understanding both is key to the project's success.Source Database SchemaThe following diagram illustrates the relational schema of the BikeStores OLTP database. This schema is highly normalized to minimize data redundancy and ensure data integrity for daily business operations.<!-- Insert Image: [DB_ DIagram.PNG] -->Data Warehouse SchemaThe Data Warehouse is designed using a Star Schema to prioritize read-performance for reporting. This model features a central FactSales table linked to several dimension tables via foreign keys.Fact Table:FactSales: This central table contains the core quantifiable measures of the business, such as Quantity, ListPrice, and the calculated NetSalesAmount. It also includes foreign keys that link it to all dimension tables.Dimension Tables:DimProduct: Details about each bike, including its brand, category, and model year.DimCustomer: Information about customers, including their name, city, and state.DimStore: Data on each store location.DimStaff: Information about the employees who processed the orders.DimDate: A dedicated table with a comprehensive list of dates and their associated temporal attributes (e.g., month, quarter, day of week).Note: The FactSales table uses three separate date keys (OrderDateKey, RequiredDateKey, and ShippedDateKey), all linking back to DimDate. This crucial design choice allows us to analyze sales from three distinct temporal perspectives: the date the order was placed, the date it was required, and the date it was actually shipped.<!-- Insert Image: [Fact Data.PNG] -->Incremental ETL Process Using SSISThe ETL pipeline was developed using SQL Server Integration Services (SSIS) to perform an incremental load. This approach efficiently processes only new or updated data, saving significant time and resources compared to a full-batch load.Loading Dimension TablesThe ETL process begins by loading the dimension tables.DimStore and DimStaff: These dimensions were loaded using a straightforward data flow as their attributes are generally static and do not require historical tracking.<!-- Insert Image: [Dim Store.PNG] --><!-- Insert Image: [Dim Staff.PNG] -->DimProduct and DimCustomer: These dimensions were loaded using the Slowly Changing Dimension (SCD) component in SSIS. I specifically implemented SCD Type 2 to track historical changes to attributes like customer email or product category, ensuring no data is lost and providing a complete history of changes over time.<!-- Insert Image: [DimProduct.PNG] --><!-- Insert Image: [DimCustomer.PNG] -->Loading the Fact TableThis data flow diagram illustrates the process for populating the FactSales table. The primary challenge here is converting the natural keys from the source data (e.g., customer_id) into the surrogate keys from our dimension tables (e.g., CustomerKey). This is accomplished by using multiple Lookup components in SSIS.<!-- Insert Image: [Fact Sales.PNG] -->Analysis and VisualizationOnce the data was loaded into the Data Warehouse, I used various tools to analyze the data and present valuable insights through interactive dashboards.Power BI DashboardsInteractive dashboards were created in Power BI to provide a comprehensive overview of business performance.Customer Analysis Dashboard: This dashboard provides a deep dive into customer behavior.KPIs: Key indicators include Total Customers, Total Net Sales, and Average Customer Sales.Visualizations: Charts highlight the highest spending customers, top discounts applied, and a trend line showing average customer sales over time.<!-- Insert Image: [Customer.PNG] -->Product Analysis Dashboard: This dashboard focuses on product performance and sales.KPIs: Key indicators include Total Orders, Total Quantity Sold, and Total Net Sales.Visualizations: The dashboard features a line chart of average list price over time, a bar chart showing sales by category, and a list of the top 10 best-selling products.<!-- Insert Image: [Product.PNG] -->Tools and Technologies UsedDatabases: SQL ServerETL: SQL Server Integration Services (SSIS)Analysis: SQLVisualization: Power BIStreaming: Python
